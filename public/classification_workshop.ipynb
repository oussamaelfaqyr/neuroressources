{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3184bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "# We use pandas to read the CSV file into a DataFrame\n",
    "df = pd.read_csv('ecommerce.csv')\n",
    "\n",
    "# Inspect the data\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46114d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Target Variable Analysis\n",
    "# We need to know if our dataset is balanced or imbalanced\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Churn', data=df, palette='viridis')\n",
    "plt.title('Target Distribution: Churn (1) vs No Churn (0)')\n",
    "plt.show()\n",
    "\n",
    "# 2. Numerical Feature Analysis\n",
    "# Let's check the statistics of our numerical columns\n",
    "display(df.describe())\n",
    "\n",
    "# 3. Correlation Heatmap\n",
    "# Checking which features are related to each other\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be02caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 3.0a: INSPECTION BEFORE CLEANING ---\n",
    "# It is crucial to check unique values to spot inconsistencies (e.g., \"Mobile\" vs \"Mobile Phone\")\n",
    "print(\"--- Unique Value Inspection ---\\n\")\n",
    "\n",
    "for col in df.columns:\n",
    "    print(f\"Feature: {col}\")\n",
    "    print(f\"Count of unique values: {df[col].nunique()}\")\n",
    "    \n",
    "    # If a column has too many unique values (like CashbackAmount), we only show the first 10 to keep output clean\n",
    "    if df[col].nunique() > 20:\n",
    "        print(f\"Values (First 10 sample): {df[col].unique()[:10]} ...\")\n",
    "    else:\n",
    "        print(f\"Values: {df[col].unique()}\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# --- STEP 3.0b: OUTLIER DETECTION ---\n",
    "\n",
    "print(\"--- Outlier Detection (IQR Method) ---\\n\")\n",
    "\n",
    "# Select only numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "for col in numerical_cols:\n",
    "    # 1. Calculate Q1 (25th %), Q3 (75th %), and IQR\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # 2. Define Bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # 3. Count Outliers\n",
    "    outliers_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
    "    \n",
    "    # Only print if outliers exist\n",
    "    if outliers_count > 0:\n",
    "        print(f\"Feature '{col}': {outliers_count} outliers ({outliers_count/len(df):.2%})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecabefb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 3.1: DATA CLEANING ---\n",
    "\n",
    "# Create a copy to keep the original loaded data safe\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Drop ID column (it's unique for every user and has no predictive power)\n",
    "# We check if it exists first to avoid errors if you run the cell twice\n",
    "if 'CustomerID' in df_clean.columns:\n",
    "    df_clean = df_clean.drop(columns=['CustomerID'])\n",
    "\n",
    "df_clean['PreferredLoginDevice'] = df_clean['PreferredLoginDevice'].replace('Mobile Phone', 'Phone')\n",
    "df_clean['PreferedOrderCat'] = df_clean['PreferedOrderCat'].replace('Mobile Phone', 'Phone')\n",
    "df_clean['PreferedOrderCat'] = df_clean['PreferedOrderCat'].replace('Mobile', 'Phone')\n",
    "# Handle Missing Values\n",
    "# Strategy: Fill numerical gaps with the Median (robust to outliers)\n",
    "for col in df_clean.columns:\n",
    "    if df_clean[col].dtype != 'object':\n",
    "        df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "\n",
    "print(\"Missing values after cleaning:\", df_clean.isnull().sum().sum())\n",
    "\n",
    "\n",
    "# --- STEP 3.2: ENCODING CATEGORICAL VARIABLES ---\n",
    "\n",
    "# Machine learning models cannot understand text. \n",
    "# We use One-Hot Encoding to convert them into binary columns (0s and 1s)\n",
    "df_final = pd.get_dummies(df_clean, drop_first=True, dtype=int)\n",
    "\n",
    "print(\"Final Data Shape:\", df_final.shape)\n",
    "display(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a0c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the specific tools for this step\n",
    "from sklearn.model_selection import ____________\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Separate Features (X) and Target (y)\n",
    "# TODO: Drop the target column 'Churn' from X\n",
    "X = df_final.drop(___, axis=1)\n",
    "y = df_final['Churn']\n",
    "\n",
    "# 2. Split into Training (80%) and Testing (20%)\n",
    "# TODO: Complete the function to split the data\n",
    "# random_state=42 ensures we get the same split every time\n",
    "X_train, X_test, y_train, y_test = ___(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Scale the Data\n",
    "# Models like KNN and Logistic Regression struggle if values aren't on the same scale\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# TODO: Fit the scaler on training data ONLY and transform it\n",
    "# Hint: Use .fit_transform()\n",
    "X_train_scaled = scaler.___(X_train)\n",
    "\n",
    "# TODO: Transform the test data using the parameters learned from training\n",
    "# Hint: Use .transform() ONLY (Do NOT fit again!)\n",
    "X_test_scaled = scaler.___(X_test)\n",
    "\n",
    "print(\"Data successfully split and scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231abe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TODO: IMPORT MODELS ---\n",
    "# Import LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, \n",
    "# RandomForestClassifier, and SVC from sklearn\n",
    "from sklearn.linear_model import ___\n",
    "from sklearn.neighbors import ___\n",
    "from sklearn.tree import ___\n",
    "from sklearn.ensemble import ___\n",
    "from sklearn.svm import ___\n",
    "\n",
    "print(\"--- Training Baseline Models ---\")\n",
    "\n",
    "# 1. Logistic Regression\n",
    "# TODO: Initialize with C=0.01 and random_state=42\n",
    "clf_log = ___(C=0.01, random_state=42)\n",
    "# TODO: Fit on training data\n",
    "clf_log.fit(X_train_scaled, y_train)\n",
    "print(\"--> Logistic Regression trained.\")\n",
    "\n",
    "\n",
    "# 2. K-Nearest Neighbors (KNN)\n",
    "# TODO: Initialize with n_neighbors=25\n",
    "clf_knn = ___(n_neighbors=25)\n",
    "clf_knn.fit(X_train_scaled, y_train)\n",
    "print(\"--> KNN trained.\")\n",
    "\n",
    "\n",
    "# 3. Decision Tree\n",
    "# TODO: Initialize with max_depth=4 and random_state=42\n",
    "clf_tree = ___(max_depth=4, random_state=42)\n",
    "clf_tree.fit(X_train_scaled, y_train)\n",
    "print(\"--> Decision Tree trained.\")\n",
    "\n",
    "\n",
    "# 4. Random Forest\n",
    "# TODO: Initialize with n_estimators=10, max_depth=5, and random_state=42\n",
    "clf_rf = ___(n_estimators=10, max_depth=5, random_state=42)\n",
    "clf_rf.fit(X_train_scaled, y_train)\n",
    "print(\"--> Random Forest trained.\")\n",
    "\n",
    "\n",
    "# 5. Support Vector Machine (SVM)\n",
    "# TODO: Initialize with kernel='sigmoid', C=0.1, and random_state=42\n",
    "clf_svm = ___(kernel='sigmoid', C=0.1, random_state=42)\n",
    "clf_svm.fit(X_train_scaled, y_train)\n",
    "print(\"--> SVM trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TODO: IMPORT METRICS ---\n",
    "# Import accuracy, precision, recall, and f1\n",
    "from sklearn.metrics import ___, ___, ___, ___\n",
    "import pandas as pd\n",
    "\n",
    "print(\"--- Baseline Evaluation Metrics ---\\n\")\n",
    "\n",
    "# 1. Create a dictionary of our trained models\n",
    "# (We use the models you just trained above)\n",
    "trained_models = {\n",
    "    \"Logistic Regression\": ___,\n",
    "    \"KNN\": ___,\n",
    "    \"Decision Tree\": ___,\n",
    "    \"Random Forest\": ___,\n",
    "    \"SVM\": ___\n",
    "}\n",
    "\n",
    "# 2. Initialize a list to store results\n",
    "results_list = []\n",
    "\n",
    "# 3. Calculate metrics for each model\n",
    "for name, model in trained_models.items():\n",
    "    # TODO: Generate predictions on the scaled TEST set\n",
    "    y_pred = model.___(X_test_scaled)\n",
    "    \n",
    "    # TODO: Calculate Scores (Compare y_test with y_pred)\n",
    "    acc = ___(y_test, y_pred)\n",
    "    prec = ___(y_test, y_pred, zero_division=0)\n",
    "    rec = ___(y_test, y_pred)\n",
    "    f1 = ___(y_test, y_pred)\n",
    "    \n",
    "    # Append to list\n",
    "    results_list.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1-Score\": f1\n",
    "    })\n",
    "\n",
    "# 4. Convert to DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# 5. Display sorted by F1-Score\n",
    "display(results_df.sort_values(by='F1-Score', ascending=False))\n",
    "\n",
    "print(\"\\nDescription of Metrics:\")\n",
    "print(\"- Accuracy:  Overall correctness\")\n",
    "print(\"- Precision: When it predicts 'Churn', how often is it right?\")\n",
    "print(\"- Recall:    Out of all actual 'Churners', how many did we catch?\")\n",
    "print(\"- F1-Score:  The harmonic mean of Precision and Recall (Balance).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aeb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TODO: IMPORT CROSS-VALIDATION TOOL ---\n",
    "from sklearn.model_selection import ___\n",
    "\n",
    "print(\"--- Cross-Validation Stability Check ---\\n\")\n",
    "\n",
    "# Group the models you trained in Step 5 into a dictionary\n",
    "models = {\n",
    "    \"Logistic Regression\": clf_log,\n",
    "    \"KNN\": clf_knn,\n",
    "    \"Decision Tree\": clf_tree,\n",
    "    \"Random Forest\": clf_rf,\n",
    "    \"SVM\": clf_svm\n",
    "}\n",
    "\n",
    "# Loop through the models to test each one\n",
    "for name, model in models.items():\n",
    "    # TODO: Run Cross-Validation\n",
    "    # - model: The model object\n",
    "    # - X, y: The TRAINING data (X_train_scaled, y_train)\n",
    "    # - cv: Number of folds (use 5)\n",
    "    # - scoring: The metric we want (use 'accuracy')\n",
    "    scores = ___(model, X_train_scaled, y_train, cv=5, scoring='___')\n",
    "    \n",
    "    # We print the Mean score and the Standard Deviation (Stability)\n",
    "    print(f\"{name}: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TODO: IMPORT GRID SEARCH ---\n",
    "from sklearn.model_selection import ___\n",
    "\n",
    "print(\"--- Starting Exhaustive Grid Search ---\\n\")\n",
    "print(\"Note: This may take a few minutes because we are testing hundreds of combinations.\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. Tune Logistic Regression\n",
    "# ==========================================\n",
    "print(\"1. Tuning Logistic Regression...\")\n",
    "\n",
    "# TODO: Define the parameter grid\n",
    "lr_grid = {\n",
    "    # Try C values: [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    'C': [___], \n",
    "    # Try solvers: ['liblinear', 'lbfgs']\n",
    "    'solver': [___],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "# TODO: Initialize GridSearchCV\n",
    "lr_search = ___(\n",
    "    estimator=LogisticRegression(random_state=42),\n",
    "    param_grid=___,\n",
    "    cv=5, \n",
    "    n_jobs=-1, \n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# TODO: Fit on the Training data\n",
    "lr_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# TODO: Get the best model\n",
    "best_log = lr_search.___\n",
    "\n",
    "print(f\"   Best LogReg Params: {lr_search.best_params_}\")\n",
    "print(f\"   Best Accuracy: {lr_search.best_score_:.4f}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. Tune K-Nearest Neighbors (KNN)\n",
    "# ==========================================\n",
    "print(\"2. Tuning KNN...\")\n",
    "\n",
    "knn_grid = {\n",
    "    # TODO: Try odd neighbors from 3 to 21 (e.g. [3, 5, 7, ...])\n",
    "    'n_neighbors': [___], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "knn_search = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=knn_grid,\n",
    "    cv=5, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "knn_search.fit(X_train_scaled, y_train)\n",
    "best_knn = knn_search.best_estimator_\n",
    "print(f\"   Best KNN Params: {knn_search.best_params_}\")\n",
    "print(f\"   Best Accuracy: {knn_search.best_score_:.4f}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. Tune Decision Tree\n",
    "# ==========================================\n",
    "print(\"3. Tuning Decision Tree...\")\n",
    "\n",
    "dt_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    # TODO: Try max_depths: [None, 5, 10, 20, 30]\n",
    "    'max_depth': [___],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "dt_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    param_grid=dt_grid,\n",
    "    cv=5, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "dt_search.fit(X_train_scaled, y_train)\n",
    "best_tree = dt_search.best_estimator_\n",
    "print(f\"   Best Tree Params: {dt_search.best_params_}\")\n",
    "print(f\"   Best Accuracy: {dt_search.best_score_:.4f}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. Tune Random Forest\n",
    "# ==========================================\n",
    "print(\"4. Tuning Random Forest...\")\n",
    "\n",
    "rf_grid = {\n",
    "    # TODO: Try n_estimators: [50, 100, 200]\n",
    "    'n_estimators': [___],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=rf_grid,\n",
    "    cv=3,       # Reduced CV to 3 for RF to save time\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_search.fit(X_train_scaled, y_train)\n",
    "best_rf = rf_search.best_estimator_\n",
    "print(f\"   Best RF Params: {rf_search.best_params_}\")\n",
    "print(f\"   Best Accuracy: {rf_search.best_score_:.4f}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 5. Tune Support Vector Machine (SVM)\n",
    "# ==========================================\n",
    "print(\"5. Tuning SVM (WARNING: This is slow)...\")\n",
    "\n",
    "svm_grid = {\n",
    "    # TODO: Try C values: [0.1, 1, 10, 100]\n",
    "    'C': [___],\n",
    "    # TODO: Try kernels: ['linear', 'rbf', 'poly']\n",
    "    'kernel': [___],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svm_search = GridSearchCV(\n",
    "    estimator=SVC(probability=True, random_state=42),\n",
    "    param_grid=svm_grid,\n",
    "    cv=3,       # Reduced CV to 3 for SVM\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "svm_search.fit(X_train_scaled, y_train)\n",
    "best_svm = svm_search.best_estimator_\n",
    "print(f\"   Best SVM Params: {svm_search.best_params_}\")\n",
    "print(f\"   Best Accuracy: {svm_search.best_score_:.4f}\\n\")\n",
    "\n",
    "print(\"--- Tuning Complete! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# --- STEP 9: Final Comparison ---\n",
    "\n",
    "print(\"--- Re-establishing Baseline Models (Weak Params) ---\")\n",
    "# We re-train these quickly to ensure the variables exist in this cell\n",
    "# (No need to change anything here, just run it to set up the comparison)\n",
    "clf_log = LogisticRegression(C=0.01, solver='liblinear', random_state=42).fit(X_train_scaled, y_train)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=20).fit(X_train_scaled, y_train)\n",
    "clf_tree = DecisionTreeClassifier(max_depth=2, random_state=42).fit(X_train_scaled, y_train)\n",
    "clf_rf = RandomForestClassifier(n_estimators=10, max_depth=3, random_state=42).fit(X_train_scaled, y_train)\n",
    "clf_svm = SVC(kernel='sigmoid', C=0.1, random_state=42).fit(X_train_scaled, y_train)\n",
    "print(\"Baselines ready.\\n\")\n",
    "\n",
    "\n",
    "print(\"--- Final Evaluation: Baseline vs. Tuned ---\\n\")\n",
    "\n",
    "# 1. Define Helper Function to calculate all 4 metrics\n",
    "def get_metrics(model, X, y):\n",
    "    # TODO: Generate predictions\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # TODO: Return a dictionary with the 4 metrics\n",
    "    return {\n",
    "        'Accuracy': ___(y, y_pred),\n",
    "        'Precision': ___(y, y_pred, zero_division=0),\n",
    "        'Recall': ___(y, y_pred),\n",
    "        'F1': ___(y, y_pred)\n",
    "    }\n",
    "\n",
    "# 2. Calculate Metrics for All Models\n",
    "comparison_list = []\n",
    "\n",
    "# Dictionary of pairs: (Baseline, Tuned)\n",
    "models_dict = {\n",
    "    \"Logistic Regression\": (clf_log, best_log),\n",
    "    \"KNN\":                 (clf_knn, best_knn),\n",
    "    \"Decision Tree\":       (clf_tree, best_tree),\n",
    "    \"Random Forest\":       (clf_rf, best_rf),\n",
    "    \"SVM\":                 (clf_svm, best_svm)\n",
    "}\n",
    "\n",
    "for name, (base_model, tuned_model) in models_dict.items():\n",
    "    # TODO: Get metrics for Baseline model using the TEST set\n",
    "    # Hint: Use X_test_scaled and y_test\n",
    "    base_metrics = get_metrics(base_model, ___, ___)\n",
    "    \n",
    "    # TODO: Get metrics for Tuned model using the TEST set\n",
    "    tuned_metrics = get_metrics(tuned_model, ___, ___)\n",
    "    \n",
    "    # Add to list\n",
    "    comparison_list.append({\n",
    "        'Model': name,\n",
    "        'Base Acc': base_metrics['Accuracy'],\n",
    "        'Tuned Acc': tuned_metrics['Accuracy'],\n",
    "        'Base F1': base_metrics['F1'],\n",
    "        'Tuned F1': tuned_metrics['F1'],\n",
    "        'Base Recall': base_metrics['Recall'],\n",
    "        'Tuned Recall': tuned_metrics['Recall']\n",
    "    })\n",
    "\n",
    "# 3. Create DataFrame\n",
    "results_df = pd.DataFrame(comparison_list)\n",
    "\n",
    "# 4. Display the detailed table (Sorted by Tuned F1 Score)\n",
    "print(\"Final Detailed Scoreboard:\")\n",
    "display(results_df.round(4).sort_values(by='Tuned F1', ascending=False))\n",
    "\n",
    "\n",
    "# 5. Visualize the Improvement\n",
    "# Reshape data for plotting\n",
    "results_melted = results_df.melt(id_vars='Model', \n",
    "                                 value_vars=['Base F1', 'Tuned F1'], \n",
    "                                 var_name='Type', \n",
    "                                 value_name='F1 Score')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# TODO: Create a barplot\n",
    "# x='Model', y='F1 Score', hue='Type'\n",
    "sns.barplot(data=results_melted, x='___', y='___', hue='___', palette='viridis')\n",
    "\n",
    "plt.title(\"Impact of Tuning on F1-Score (The Real Value)\")\n",
    "plt.ylim(0.0, 1.0) \n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 6. Conclusion\n",
    "best_model = results_df.loc[results_df['Tuned F1'].idxmax()]\n",
    "print(f\"üèÜ Best Model: {best_model['Model']}\")\n",
    "print(f\"   Recall improved from {best_model['Base Recall']:.2f} to {best_model['Tuned Recall']:.2f}\")\n",
    "print(f\"   (This means we catch more churners!)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
